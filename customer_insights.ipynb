{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d9d9b3d",
   "metadata": {},
   "source": [
    "# Comprehensive Sales Analysis - Customer Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227fda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway, ttest_ind, chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6679e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPREHENSIVE SALES ANALYSIS FRAMEWORK ===\n",
      "Libraries loaded successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set styling\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=== COMPREHENSIVE SALES ANALYSIS FRAMEWORK ===\")\n",
    "print(\"Libraries loaded successfully!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce843c41",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# PHASE 1: DATA FOUNDATION & QUALITY ASSESSMENT\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b215adb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 1: DATA FOUNDATION & QUALITY ASSESSMENT\n",
      "==================================================\n",
      "Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"PHASE 1: DATA FOUNDATION & QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    sales_data = pd.read_csv('sales_data.csv')\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: sales_data.csv not found. Please ensure the file is in the correct directory.\")\n",
    "    exit(1)\n",
    "df = pd.DataFrame(sales_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225dc9c7",
   "metadata": {},
   "source": [
    "# 1.1 Data Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6831a20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 DATA AUDIT\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dataset shape: (16, 11)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "Customer_ID           0\n",
      "Customer_Name         0\n",
      "Region                0\n",
      "Total_Spend           0\n",
      "Purchase_Frequency    0\n",
      "Marketing_Spend       0\n",
      "Seasonality_Index     0\n",
      "Churned               0\n",
      "Marketing_ROI         0\n",
      "Spend_per_Purchase    0\n",
      "Churned_Binary        0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "Customer_ID             int64\n",
      "Customer_Name          object\n",
      "Region                 object\n",
      "Total_Spend             int64\n",
      "Purchase_Frequency      int64\n",
      "Marketing_Spend         int64\n",
      "Seasonality_Index     float64\n",
      "Churned                object\n",
      "Marketing_ROI         float64\n",
      "Spend_per_Purchase    float64\n",
      "Churned_Binary          int64\n",
      "dtype: object\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Customer_ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Customer_Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Total_Spend",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Purchase_Frequency",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Marketing_Spend",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Seasonality_Index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Churned",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Marketing_ROI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Spend_per_Purchase",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Churned_Binary",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "38a9c5a5-87bd-49ea-8cc8-31c0c20092f1",
       "rows": [
        [
         "0",
         "101",
         "John Doe",
         "North",
         "5000",
         "12",
         "2000",
         "1.2",
         "No",
         "2.5",
         "416.6666666666667",
         "0"
        ],
        [
         "1",
         "102",
         "Jane Smith",
         "South",
         "3000",
         "8",
         "1500",
         "1.0",
         "Yes",
         "2.0",
         "375.0",
         "1"
        ],
        [
         "2",
         "103",
         "Sam Brown",
         "East",
         "4500",
         "10",
         "1800",
         "1.1",
         "No",
         "2.5",
         "450.0",
         "0"
        ],
        [
         "3",
         "104",
         "Linda Johnson",
         "West",
         "2500",
         "5",
         "1000",
         "0.9",
         "Yes",
         "2.5",
         "500.0",
         "1"
        ],
        [
         "4",
         "105",
         "Michael Lee",
         "North",
         "7000",
         "15",
         "2500",
         "1.3",
         "No",
         "2.8",
         "466.6666666666667",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Customer_Name</th>\n",
       "      <th>Region</th>\n",
       "      <th>Total_Spend</th>\n",
       "      <th>Purchase_Frequency</th>\n",
       "      <th>Marketing_Spend</th>\n",
       "      <th>Seasonality_Index</th>\n",
       "      <th>Churned</th>\n",
       "      <th>Marketing_ROI</th>\n",
       "      <th>Spend_per_Purchase</th>\n",
       "      <th>Churned_Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>North</td>\n",
       "      <td>5000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>No</td>\n",
       "      <td>2.5</td>\n",
       "      <td>416.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>South</td>\n",
       "      <td>3000</td>\n",
       "      <td>8</td>\n",
       "      <td>1500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Sam Brown</td>\n",
       "      <td>East</td>\n",
       "      <td>4500</td>\n",
       "      <td>10</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.1</td>\n",
       "      <td>No</td>\n",
       "      <td>2.5</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Linda Johnson</td>\n",
       "      <td>West</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.5</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Michael Lee</td>\n",
       "      <td>North</td>\n",
       "      <td>7000</td>\n",
       "      <td>15</td>\n",
       "      <td>2500</td>\n",
       "      <td>1.3</td>\n",
       "      <td>No</td>\n",
       "      <td>2.8</td>\n",
       "      <td>466.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_ID  Customer_Name Region  Total_Spend  Purchase_Frequency  \\\n",
       "0          101       John Doe  North         5000                  12   \n",
       "1          102     Jane Smith  South         3000                   8   \n",
       "2          103      Sam Brown   East         4500                  10   \n",
       "3          104  Linda Johnson   West         2500                   5   \n",
       "4          105    Michael Lee  North         7000                  15   \n",
       "\n",
       "   Marketing_Spend  Seasonality_Index Churned  Marketing_ROI  \\\n",
       "0             2000                1.2      No            2.5   \n",
       "1             1500                1.0     Yes            2.0   \n",
       "2             1800                1.1      No            2.5   \n",
       "3             1000                0.9     Yes            2.5   \n",
       "4             2500                1.3      No            2.8   \n",
       "\n",
       "   Spend_per_Purchase  Churned_Binary  \n",
       "0          416.666667               0  \n",
       "1          375.000000               1  \n",
       "2          450.000000               0  \n",
       "3          500.000000               1  \n",
       "4          466.666667               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"1.1 DATA AUDIT\")\n",
    "print(\"-\" * 20)\n",
    "display(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280af5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Derived metrics created: Marketing_ROI, Spend_per_Purchase, Churned_Binary\n"
     ]
    }
   ],
   "source": [
    "# Create derived metrics\n",
    "df['Marketing_ROI'] = df['Total_Spend'] / df['Marketing_Spend']\n",
    "df['Spend_per_Purchase'] = df['Total_Spend'] / df['Purchase_Frequency']\n",
    "df['Churned_Binary'] = df['Churned'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "print(f\"\\nDerived metrics created: Marketing_ROI, Spend_per_Purchase, Churned_Binary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f22973d",
   "metadata": {},
   "source": [
    "# 1.2 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e0d01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.2 EXPLORATORY DATA ANALYSIS\n",
      "------------------------------\n",
      "Descriptive Statistics:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Customer_ID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total_Spend",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Purchase_Frequency",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Marketing_Spend",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Seasonality_Index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Marketing_ROI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Spend_per_Purchase",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Churned_Binary",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "79368053-2dc1-4088-bd6d-99ad8bef7e1e",
       "rows": [
        [
         "count",
         "16.0",
         "16.0",
         "16.0",
         "16.0",
         "16.0",
         "16.0",
         "16.0",
         "16.0"
        ],
        [
         "mean",
         "108.5",
         "4137.5",
         "9.5",
         "1675.0",
         "1.04375",
         "2.449537827088772",
         "440.25916791541795",
         "0.5"
        ],
        [
         "std",
         "4.760952285695233",
         "1396.1255912942313",
         "3.22490309931942",
         "484.42405665559863",
         "0.15478479684172256",
         "0.19774138678451184",
         "45.277209377711934",
         "0.5163977794943222"
        ],
        [
         "min",
         "101.0",
         "2500.0",
         "5.0",
         "1000.0",
         "0.8",
         "2.0",
         "366.6666666666667",
         "0.0"
        ],
        [
         "25%",
         "104.75",
         "2975.0",
         "6.75",
         "1300.0",
         "0.9",
         "2.3023349436392913",
         "409.375",
         "0.0"
        ],
        [
         "50%",
         "108.5",
         "3900.0",
         "9.5",
         "1650.0",
         "1.05",
         "2.474937343358396",
         "450.0",
         "0.5"
        ],
        [
         "75%",
         "112.25",
         "5075.0",
         "12.0",
         "2025.0",
         "1.2",
         "2.5297619047619047",
         "462.8205128205128",
         "1.0"
        ],
        [
         "max",
         "116.0",
         "7000.0",
         "15.0",
         "2500.0",
         "1.3",
         "2.8",
         "520.0",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Total_Spend</th>\n",
       "      <th>Purchase_Frequency</th>\n",
       "      <th>Marketing_Spend</th>\n",
       "      <th>Seasonality_Index</th>\n",
       "      <th>Marketing_ROI</th>\n",
       "      <th>Spend_per_Purchase</th>\n",
       "      <th>Churned_Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>108.500000</td>\n",
       "      <td>4137.500000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>1675.000000</td>\n",
       "      <td>1.043750</td>\n",
       "      <td>2.449538</td>\n",
       "      <td>440.259168</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.760952</td>\n",
       "      <td>1396.125591</td>\n",
       "      <td>3.224903</td>\n",
       "      <td>484.424057</td>\n",
       "      <td>0.154785</td>\n",
       "      <td>0.197741</td>\n",
       "      <td>45.277209</td>\n",
       "      <td>0.516398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>366.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>104.750000</td>\n",
       "      <td>2975.000000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.302335</td>\n",
       "      <td>409.375000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>108.500000</td>\n",
       "      <td>3900.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>1650.000000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>2.474937</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112.250000</td>\n",
       "      <td>5075.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2025.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.529762</td>\n",
       "      <td>462.820513</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Customer_ID  Total_Spend  Purchase_Frequency  Marketing_Spend  \\\n",
       "count    16.000000    16.000000           16.000000        16.000000   \n",
       "mean    108.500000  4137.500000            9.500000      1675.000000   \n",
       "std       4.760952  1396.125591            3.224903       484.424057   \n",
       "min     101.000000  2500.000000            5.000000      1000.000000   \n",
       "25%     104.750000  2975.000000            6.750000      1300.000000   \n",
       "50%     108.500000  3900.000000            9.500000      1650.000000   \n",
       "75%     112.250000  5075.000000           12.000000      2025.000000   \n",
       "max     116.000000  7000.000000           15.000000      2500.000000   \n",
       "\n",
       "       Seasonality_Index  Marketing_ROI  Spend_per_Purchase  Churned_Binary  \n",
       "count          16.000000      16.000000           16.000000       16.000000  \n",
       "mean            1.043750       2.449538          440.259168        0.500000  \n",
       "std             0.154785       0.197741           45.277209        0.516398  \n",
       "min             0.800000       2.000000          366.666667        0.000000  \n",
       "25%             0.900000       2.302335          409.375000        0.000000  \n",
       "50%             1.050000       2.474937          450.000000        0.500000  \n",
       "75%             1.200000       2.529762          462.820513        1.000000  \n",
       "max             1.300000       2.800000          520.000000        1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n1.2 EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Descriptive statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Correlation analysis\n",
    "numerical_cols = ['Total_Spend', 'Purchase_Frequency', 'Marketing_Spend', 'Seasonality_Index', 'Marketing_ROI', 'Spend_per_Purchase']\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f36a8be",
   "metadata": {},
   "source": [
    "### 1.3 Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c242762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Missing Values Before Handling ---\n",
      "Customer_ID           0\n",
      "Customer_Name         0\n",
      "Region                0\n",
      "Total_Spend           0\n",
      "Purchase_Frequency    0\n",
      "Marketing_Spend       0\n",
      "Seasonality_Index     0\n",
      "Churned               0\n",
      "Marketing_ROI         0\n",
      "Spend_per_Purchase    0\n",
      "Churned_Binary        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Finding missing values\n",
    "print(\"\\n--- Missing Values Before Handling ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "if df.isnull().values.any():\n",
    "    # Fill missing values with mean for numerical columns\n",
    "    df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())\n",
    "    # Fill missing values with mode for categorical columns\n",
    "    df['Churned'] = df['Churned'].fillna(df['Churned'].mode()[0])\n",
    "    print(\"\\n--- Missing Values After Handling ---\")\n",
    "    print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87062160",
   "metadata": {},
   "source": [
    "### 1.4 Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39027cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Duplicate Rows Before Handling ---\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "Duplicate rows (based on 'Customer_ID') removed.\n",
      "Number of duplicate rows after removal: 0\n",
      "New dataset shape after duplicate removal: Rows = 16, Columns = 11\n"
     ]
    }
   ],
   "source": [
    "# Handling Duplicate Values\n",
    "print(\"\\n--- Duplicate Rows Before Handling ---\")\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Identify and display duplicate rows based on Customer_ID (optional, for inspection)\n",
    "# Assuming Customer_ID should be unique. If entire row duplicates, df.duplicated() without subset is fine.\n",
    "if df.duplicated(subset='Customer_ID').any():\n",
    "    print(\"Duplicate Customer_ID entries identified:\")\n",
    "    print(df[df.duplicated(subset='Customer_ID', keep=False)].sort_values(by='Customer_ID'))\n",
    "\n",
    "# Remove duplicate rows based on 'Customer_ID', keeping the first occurrence\n",
    "df.drop_duplicates(subset='Customer_ID', keep='first', inplace=True)\n",
    "print(\"\\nDuplicate rows (based on 'Customer_ID') removed.\")\n",
    "print(f\"Number of duplicate rows after removal: {df.duplicated().sum()}\")\n",
    "\n",
    "print(f\"New dataset shape after duplicate removal: Rows = {df.shape[0]}, Columns = {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16468236",
   "metadata": {},
   "source": [
    "### 1.5 Datatype Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "159e37e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Types Before Conversion ---\n",
      "Customer_ID             int64\n",
      "Customer_Name          object\n",
      "Region                 object\n",
      "Total_Spend             int64\n",
      "Purchase_Frequency      int64\n",
      "Marketing_Spend         int64\n",
      "Seasonality_Index     float64\n",
      "Churned                object\n",
      "Marketing_ROI         float64\n",
      "Spend_per_Purchase    float64\n",
      "Churned_Binary          int64\n",
      "dtype: object\n",
      "'Customer_ID' converted to int.\n",
      "'Total_Spend' column converted to numeric.\n",
      "'Purchase_Frequency' column converted to numeric.\n",
      "'Marketing_Spend' column converted to numeric.\n",
      "'Seasonality_Index' column converted to numeric.\n",
      "'Churned' column converted to 0 (No) / 1 (Yes).\n",
      "\n",
      "--- Data Types After Conversion ---\n",
      "Customer_ID             int32\n",
      "Customer_Name          object\n",
      "Region                 object\n",
      "Total_Spend             int64\n",
      "Purchase_Frequency      int64\n",
      "Marketing_Spend         int64\n",
      "Seasonality_Index     float64\n",
      "Churned                 int32\n",
      "Marketing_ROI         float64\n",
      "Spend_per_Purchase    float64\n",
      "Churned_Binary          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Markdown heading for this section\n",
    "# ### 5. Data Type Conversion\n",
    "\n",
    "print(\"\\n--- Data Types Before Conversion ---\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert 'Customer_ID' to integer (handle non-numeric first by coercing to NaN, though not expected from this dataset)\n",
    "if 'Customer_ID' in df.columns:\n",
    "    df['Customer_ID'] = pd.to_numeric(df['Customer_ID'], errors='coerce')\n",
    "    if df['Customer_ID'].isnull().any():\n",
    "        print(\"Warning: Non-numeric Customer_ID values detected and converted to NaN. Review data source.\")\n",
    "        # Decide how to handle: drop rows, or impute with unique new IDs. For now, drop.\n",
    "        df.dropna(subset=['Customer_ID'], inplace=True)\n",
    "    df['Customer_ID'] = df['Customer_ID'].astype(int)\n",
    "    print(\"'Customer_ID' converted to int.\")\n",
    "\n",
    "\n",
    "# Convert numerical columns to appropriate types and handle NaNs after conversion\n",
    "numerical_cols_to_convert = ['Total_Spend', 'Purchase_Frequency', 'Marketing_Spend', 'Seasonality_Index']\n",
    "for col in numerical_cols_to_convert:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        # Impute NaNs after conversion with the median\n",
    "        if df[col].isnull().any():\n",
    "            median_val = df[col].median()\n",
    "            df[col].fillna(median_val, inplace=True)\n",
    "            print(f\"'{col}' column: Non-numeric values converted to NaN and then imputed with median ({median_val}).\")\n",
    "        else:\n",
    "            print(f\"'{col}' column converted to numeric.\")\n",
    "\n",
    "# Convert 'Churned' to numerical (0 for 'No', 1 for 'Yes')\n",
    "if 'Churned' in df.columns:\n",
    "    # Ensure all values are handled, case-insensitively\n",
    "    df['Churned'] = df['Churned'].str.strip().str.lower().map({'yes': 1, 'no': 0})\n",
    "    # Handle any unmapped values (e.g., set to NaN and then impute or drop)\n",
    "    if df['Churned'].isnull().any():\n",
    "        print(\"Warning: Some 'Churned' values could not be mapped to 0/1. These will be set to the mode.\")\n",
    "        df['Churned'].fillna(df['Churned'].mode()[0], inplace=True)\n",
    "    df['Churned'] = df['Churned'].astype(int)\n",
    "    print(\"'Churned' column converted to 0 (No) / 1 (Yes).\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Data Types After Conversion ---\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18a8f59",
   "metadata": {},
   "source": [
    "### 1.6 Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "868a3843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Outlier Detection and Handling ---\n",
      "No significant outliers detected in 'Total_Spend' using IQR method.\n",
      "No significant outliers detected in 'Purchase_Frequency' using IQR method.\n",
      "No significant outliers detected in 'Marketing_Spend' using IQR method.\n",
      "No significant outliers detected in 'Seasonality_Index' using IQR method.\n",
      "\n",
      "--- Descriptive Statistics After Outlier Handling (Numerical Columns) ---\n",
      "       Total_Spend  Purchase_Frequency  Marketing_Spend  Seasonality_Index\n",
      "count    16.000000           16.000000        16.000000          16.000000\n",
      "mean   4137.500000            9.500000      1675.000000           1.043750\n",
      "std    1396.125591            3.224903       484.424057           0.154785\n",
      "min    2500.000000            5.000000      1000.000000           0.800000\n",
      "25%    2975.000000            6.750000      1300.000000           0.900000\n",
      "50%    3900.000000            9.500000      1650.000000           1.050000\n",
      "75%    5075.000000           12.000000      2025.000000           1.200000\n",
      "max    7000.000000           15.000000      2500.000000           1.300000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Outlier Detection and Handling ---\")\n",
    "\n",
    "# Define numerical columns for outlier handling\n",
    "numerical_cols_for_outliers = ['Total_Spend', 'Purchase_Frequency', 'Marketing_Spend', 'Seasonality_Index']\n",
    "\n",
    "for col in numerical_cols_for_outliers:\n",
    "    if col in df.columns:\n",
    "        # For 'Purchase_Frequency', replace negative values with median\n",
    "        if col == 'Purchase_Frequency':\n",
    "            median_val = df[col].median()\n",
    "            initial_negative = df[df[col] < 0].shape[0]\n",
    "            if initial_negative > 0:\n",
    "                df[col] = df[col].apply(lambda x: median_val if x < 0 else x)\n",
    "                print(f\"Negative values in '{col}' ({initial_negative} instances) handled by imputing with median.\")\n",
    "\n",
    "        # Using IQR method for outlier detection and capping\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers_mask = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "        initial_outliers = df[outliers_mask].shape[0]\n",
    "\n",
    "        if initial_outliers > 0:\n",
    "            # Cap outliers\n",
    "            df[col] = df[col].apply(lambda x: lower_bound if x < lower_bound else (upper_bound if x > upper_bound else x))\n",
    "            print(f\"Outliers in '{col}' ({initial_outliers} instances) detected using IQR and handled (capped).\")\n",
    "            print(f\"  Lower Bound: {lower_bound:.2f}, Upper Bound: {upper_bound:.2f}\")\n",
    "        else:\n",
    "            print(f\"No significant outliers detected in '{col}' using IQR method.\")\n",
    "\n",
    "print(\"\\n--- Descriptive Statistics After Outlier Handling (Numerical Columns) ---\")\n",
    "print(df[numerical_cols_for_outliers].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143052f0",
   "metadata": {},
   "source": [
    "### 1.7 Data Normalisation/Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb93b776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Scaling (Standardization) ---\n",
      "Columns ['Total_Spend', 'Purchase_Frequency', 'Marketing_Spend', 'Seasonality_Index'] have been standardized.\n",
      "\n",
      "--- First 5 rows after standardization (scaled columns) ---\n",
      "   Total_Spend  Purchase_Frequency  Marketing_Spend  Seasonality_Index\n",
      "0     0.638042            0.800641         0.692902           1.042572\n",
      "1    -0.841475           -0.480384        -0.373101          -0.291920\n",
      "2     0.268162            0.160128         0.266501           0.375326\n",
      "3    -1.211354           -1.441153        -1.439105          -0.959166\n",
      "4     2.117558            1.761410         1.758906           1.709818\n"
     ]
    }
   ],
   "source": [
    "# Data Standardization/Normalization (Feature Scaling)\n",
    "\n",
    "print(\"\\n--- Feature Scaling (Standardization) ---\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define numerical columns to scale (excluding IDs and binary target 'Churned')\n",
    "numerical_cols_to_scale = ['Total_Spend', 'Purchase_Frequency', 'Marketing_Spend', 'Seasonality_Index']\n",
    "\n",
    "# Check if columns exist before scaling\n",
    "existing_numerical_cols_to_scale = [col for col in numerical_cols_to_scale if col in df.columns]\n",
    "\n",
    "if existing_numerical_cols_to_scale:\n",
    "    # Apply standardization\n",
    "    df[existing_numerical_cols_to_scale] = scaler.fit_transform(df[existing_numerical_cols_to_scale])\n",
    "    print(f\"Columns {existing_numerical_cols_to_scale} have been standardized.\")\n",
    "    print(\"\\n--- First 5 rows after standardization (scaled columns) ---\")\n",
    "    print(df[existing_numerical_cols_to_scale].head())\n",
    "else:\n",
    "    print(\"No numerical columns found for standardization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121949a3",
   "metadata": {},
   "source": [
    "### 1.8 Handling Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef17324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Categorical Data Encoding ---\n",
      "Categorical columns ['Region'] have been One-Hot Encoded.\n",
      "\n",
      "--- First 5 rows after One-Hot Encoding ---\n",
      "   Customer_ID  Customer_Name  Total_Spend  Purchase_Frequency  \\\n",
      "0          101       John Doe     0.638042            0.800641   \n",
      "1          102     Jane Smith    -0.841475           -0.480384   \n",
      "2          103      Sam Brown     0.268162            0.160128   \n",
      "3          104  Linda Johnson    -1.211354           -1.441153   \n",
      "4          105    Michael Lee     2.117558            1.761410   \n",
      "\n",
      "   Marketing_Spend  Seasonality_Index  Churned  Marketing_ROI  \\\n",
      "0         0.692902           1.042572        0            2.5   \n",
      "1        -0.373101          -0.291920        1            2.0   \n",
      "2         0.266501           0.375326        0            2.5   \n",
      "3        -1.439105          -0.959166        1            2.5   \n",
      "4         1.758906           1.709818        0            2.8   \n",
      "\n",
      "   Spend_per_Purchase  Churned_Binary  Region_North  Region_South  Region_West  \n",
      "0          416.666667               0          True         False        False  \n",
      "1          375.000000               1         False          True        False  \n",
      "2          450.000000               0         False         False        False  \n",
      "3          500.000000               1         False         False         True  \n",
      "4          466.666667               0          True         False        False  \n"
     ]
    }
   ],
   "source": [
    "# 8. Handling Categorical Data\n",
    "\n",
    "print(\"\\n--- Categorical Data Encoding ---\")\n",
    "\n",
    "# Apply One-Hot Encoding to 'Region'\n",
    "# 'Churned' has already been converted to 0/1 in the data type conversion step.\n",
    "categorical_cols_to_encode = ['Region']\n",
    "\n",
    "# Check if columns exist before encoding\n",
    "existing_categorical_cols_to_encode = [col for col in categorical_cols_to_encode if col in df.columns]\n",
    "\n",
    "if existing_categorical_cols_to_encode:\n",
    "    # Using get_dummies for one-hot encoding, drop_first avoids multicollinearity\n",
    "    df = pd.get_dummies(df, columns=existing_categorical_cols_to_encode, drop_first=True)\n",
    "    print(f\"Categorical columns {existing_categorical_cols_to_encode} have been One-Hot Encoded.\")\n",
    "    print(\"\\n--- First 5 rows after One-Hot Encoding ---\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"No specified categorical columns found for encoding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e399e0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
